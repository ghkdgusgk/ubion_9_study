{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2588,"status":"ok","timestamp":1711002957787,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"om2R6J2T0Jg9"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","\n","plt.rcParams['font.family'] = 'NanumGothic'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35403,"status":"ok","timestamp":1711002993186,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"T_cDgnYb0Kwy","outputId":"f168cd95-f06a-4496-c947-e60bbd5d3f57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":453,"status":"ok","timestamp":1711005094301,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"TWGSDgLi0Poe"},"outputs":[],"source":["minor = pd.read_csv('./drive/MyDrive/공유문서함/상장csv/240317상장비주력_stand.csv', index_col=0)\n","minor_test = pd.read_csv('./drive/MyDrive/공유문서함/상장csv/240318상장비주력test_stand.csv', index_col=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjbU4DzN1hkK"},"outputs":[],"source":["# major.drop(['회사명',\n","#   '회계년도',\n","#   '설립일',\n","#   '상장일',\n","#   '상장폐지일',\n","#   '상장협 산업분류(소분류)_x',\n","#   '상장협 산업분류(중분류)_x',\n","#   '회계년',\n","#   'Unnamed: 0'], axis=1, inplace=True)"]},{"cell_type":"markdown","source":["##### train_df, test_df 설정"],"metadata":{"id":"4qvIej2pB7rO"}},{"cell_type":"code","source":["train_df = minor[['유보액대비율', '총자본투자효율', '지급이자율',\n"," '당좌자산회전률', '자본', '매입채무회전률','매입채무회전기간',\n"," '자기자본순이익률', '매출채권회전률', '자본분배율', '유연탄가격',\n"," '타인자본회전률','유보율','부실']]"],"metadata":{"id":"pCqFkigqPmVr","executionInfo":{"status":"ok","timestamp":1711006057315,"user_tz":-540,"elapsed":681,"user":{"displayName":"김현아","userId":"04855751482690087207"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["test_df = minor_test[['유보액대비율', '총자본투자효율', '지급이자율',\n"," '당좌자산회전률', '자본', '매입채무회전률','매입채무회전기간',\n"," '자기자본순이익률', '매출채권회전률', '자본분배율', '유연탄가격',\n"," '타인자본회전률','유보율','부실']]"],"metadata":{"id":"uMC8f485Qper","executionInfo":{"status":"ok","timestamp":1711006057895,"user_tz":-540,"elapsed":2,"user":{"displayName":"김현아","userId":"04855751482690087207"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["train_df.reset_index(drop=True,inplace=True)\n","test_df.reset_index(drop=True,inplace=True)"],"metadata":{"id":"AG0AnqWt5tM3","executionInfo":{"status":"ok","timestamp":1711006059299,"user_tz":-540,"elapsed":3,"user":{"displayName":"김현아","userId":"04855751482690087207"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["x_train = train_df.drop(\"부실\",axis=1)\n","y_train = train_df[\"부실\"]\n","x_test =test_df.drop(\"부실\",axis=1)\n","y_test = test_df[\"부실\"]"],"metadata":{"id":"irGMaa3BI6Ah","executionInfo":{"status":"ok","timestamp":1711007516503,"user_tz":-540,"elapsed":493,"user":{"displayName":"김현아","userId":"04855751482690087207"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["x_test =test_df.drop(\"부실\",axis=1)\n","y_test = test_df[\"부실\"]"],"metadata":{"id":"O_MZP7Gn6_w8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Urf7YzfpwQWA"},"outputs":[],"source":["# 성능확인 코드\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n","from sklearn.metrics import f1_score, roc_auc_score, average_precision_score\n","\n","def get_clf_eval(y_test, pred):\n","    confusion = confusion_matrix(y_test, pred)\n","    accuracy = accuracy_score(y_test, pred)\n","    precision = precision_score(y_test, pred)\n","    recall = recall_score(y_test, pred)\n","    roc_score = roc_auc_score(y_test, pred)\n","    pr_score = average_precision_score(y_test, pred)\n","    f1 = f1_score(y_test, pred)\n","    print('오차행렬')\n","    print(confusion)\n","    print('정확도: {0:.4f}, 정밀도 : {1:.4f}, 재현율:{2:.4f},F1 스코어:{3:.4f}'.format(accuracy, precision, recall, f1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":412,"status":"ok","timestamp":1710842197525,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"35poFbJsyU6F","outputId":"431b2bb9-9494-4ec3-896e-2e10c9d18752"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    3431\n","1.0      54\n","Name: 부실, dtype: int64"]},"metadata":{},"execution_count":9}],"source":["y_train.value_counts()"]},{"cell_type":"code","source":["from imblearn.under_sampling import RandomUnderSampler\n","\n","# RandomUnderSampler 객체 생성\n","under = RandomUnderSampler(random_state=4, sampling_strategy=0.3)\n","\n","# RandomUnderSampler를 사용하여 샘플링된 특징 및 타겟 데이터 생성\n","x_resampled, y_resampled = under.fit_resample(x_train, y_train)\n","\n","y_resampled.value_counts()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1710970575190,"user_tz":-540,"elapsed":735,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"57e822e9-4006-48c7-e031-d738b7aad2f9","id":"PG6kvyusRqsA"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0    180\n","1.0     54\n","Name: 부실, dtype: int64"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# from imblearn.over_sampling import RandomOverSampler\n","\n","# x_resampled2, y_resampled2 = RandomOverSampler(random_state=4, sampling_strategy=1).fit_resample(x_resampled, y_resampled )\n","# print(x_train.shape)\n","# y_resampled2.value_counts()"],"metadata":{"executionInfo":{"status":"ok","timestamp":1710826791091,"user_tz":-540,"elapsed":369,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cbf353bb-6fe3-4000-a3cb-3afd98ce1cfb","id":"GoEJ3nyXRqsB"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3485, 13)\n"]},{"output_type":"execute_result","data":{"text/plain":["0.0    540\n","1.0    540\n","Name: 부실, dtype: int64"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"Si1QLaOZn5jk"},"source":["#### 1. Tabnet"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106436,"status":"ok","timestamp":1711005836851,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"UqDry6_9oFeL","outputId":"fb4184d9-9ee9-453f-b2b9-046a3d1b8933"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-tabnet\n","  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.25.2)\n","Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n","Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n","Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.2.1+cu121)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-tabnet\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 pytorch-tabnet-4.1.0\n"]}],"source":["!pip install pytorch-tabnet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21929,"status":"ok","timestamp":1710842255825,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"l5swkx5woLJV","outputId":"9868bbdc-4ea0-46bf-b54c-a68a862bb264"},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 0  | loss: 0.0     |  0:00:00s\n","epoch 1  | loss: 0.0     |  0:00:00s\n","epoch 2  | loss: 0.0     |  0:00:00s\n","epoch 3  | loss: 0.0     |  0:00:00s\n","epoch 4  | loss: 0.0     |  0:00:00s\n","epoch 5  | loss: 0.0     |  0:00:00s\n","epoch 6  | loss: 0.0     |  0:00:00s\n","epoch 7  | loss: 0.0     |  0:00:00s\n","epoch 8  | loss: 0.0     |  0:00:00s\n","epoch 9  | loss: 0.0     |  0:00:00s\n","epoch 10 | loss: 0.0     |  0:00:00s\n","epoch 11 | loss: 0.0     |  0:00:00s\n","epoch 12 | loss: 0.0     |  0:00:00s\n","epoch 13 | loss: 0.0     |  0:00:00s\n","epoch 14 | loss: 0.0     |  0:00:00s\n","epoch 15 | loss: 0.0     |  0:00:00s\n","epoch 16 | loss: 0.0     |  0:00:00s\n","epoch 17 | loss: 0.0     |  0:00:00s\n","epoch 18 | loss: 0.0     |  0:00:00s\n","epoch 19 | loss: 0.0     |  0:00:00s\n","epoch 20 | loss: 0.0     |  0:00:00s\n","epoch 21 | loss: 0.0     |  0:00:00s\n","epoch 22 | loss: 0.0     |  0:00:00s\n","epoch 23 | loss: 0.0     |  0:00:00s\n","epoch 24 | loss: 0.0     |  0:00:00s\n","epoch 25 | loss: 0.0     |  0:00:00s\n","epoch 26 | loss: 0.0     |  0:00:00s\n","epoch 27 | loss: 0.0     |  0:00:00s\n","epoch 28 | loss: 0.0     |  0:00:00s\n","epoch 29 | loss: 0.0     |  0:00:00s\n","epoch 30 | loss: 0.0     |  0:00:00s\n","epoch 31 | loss: 0.0     |  0:00:00s\n","epoch 32 | loss: 0.0     |  0:00:00s\n","epoch 33 | loss: 0.0     |  0:00:00s\n","epoch 34 | loss: 0.0     |  0:00:00s\n","epoch 35 | loss: 0.0     |  0:00:00s\n","epoch 36 | loss: 0.0     |  0:00:00s\n","epoch 37 | loss: 0.0     |  0:00:00s\n","epoch 38 | loss: 0.0     |  0:00:00s\n","epoch 39 | loss: 0.0     |  0:00:00s\n","epoch 40 | loss: 0.0     |  0:00:00s\n","epoch 41 | loss: 0.0     |  0:00:00s\n","epoch 42 | loss: 0.0     |  0:00:00s\n","epoch 43 | loss: 0.0     |  0:00:00s\n","epoch 44 | loss: 0.0     |  0:00:00s\n","epoch 45 | loss: 0.0     |  0:00:00s\n","epoch 46 | loss: 0.0     |  0:00:00s\n","epoch 47 | loss: 0.0     |  0:00:00s\n","epoch 48 | loss: 0.0     |  0:00:00s\n","epoch 49 | loss: 0.0     |  0:00:00s\n","epoch 50 | loss: 0.0     |  0:00:00s\n","epoch 51 | loss: 0.0     |  0:00:00s\n","epoch 52 | loss: 0.0     |  0:00:00s\n","epoch 53 | loss: 0.0     |  0:00:00s\n","epoch 54 | loss: 0.0     |  0:00:00s\n","epoch 55 | loss: 0.0     |  0:00:00s\n","epoch 56 | loss: 0.0     |  0:00:00s\n","epoch 57 | loss: 0.0     |  0:00:00s\n","epoch 58 | loss: 0.0     |  0:00:00s\n","epoch 59 | loss: 0.0     |  0:00:00s\n","epoch 60 | loss: 0.0     |  0:00:00s\n","epoch 61 | loss: 0.0     |  0:00:00s\n","epoch 62 | loss: 0.0     |  0:00:00s\n","epoch 63 | loss: 0.0     |  0:00:00s\n","epoch 64 | loss: 0.0     |  0:00:00s\n","epoch 65 | loss: 0.0     |  0:00:00s\n","epoch 66 | loss: 0.0     |  0:00:00s\n","epoch 67 | loss: 0.0     |  0:00:00s\n","epoch 68 | loss: 0.0     |  0:00:00s\n","epoch 69 | loss: 0.0     |  0:00:00s\n","epoch 70 | loss: 0.0     |  0:00:00s\n","epoch 71 | loss: 0.0     |  0:00:00s\n","epoch 72 | loss: 0.0     |  0:00:00s\n","epoch 73 | loss: 0.0     |  0:00:00s\n","epoch 74 | loss: 0.0     |  0:00:00s\n","epoch 75 | loss: 0.0     |  0:00:00s\n","epoch 76 | loss: 0.0     |  0:00:00s\n","epoch 77 | loss: 0.0     |  0:00:00s\n","epoch 78 | loss: 0.0     |  0:00:00s\n","epoch 79 | loss: 0.0     |  0:00:00s\n","epoch 80 | loss: 0.0     |  0:00:00s\n","epoch 81 | loss: 0.0     |  0:00:00s\n","epoch 82 | loss: 0.0     |  0:00:00s\n","epoch 83 | loss: 0.0     |  0:00:00s\n","epoch 84 | loss: 0.0     |  0:00:00s\n","epoch 85 | loss: 0.0     |  0:00:00s\n","epoch 86 | loss: 0.0     |  0:00:00s\n","epoch 87 | loss: 0.0     |  0:00:00s\n","epoch 88 | loss: 0.0     |  0:00:00s\n","epoch 89 | loss: 0.0     |  0:00:00s\n","epoch 90 | loss: 0.0     |  0:00:00s\n","epoch 91 | loss: 0.0     |  0:00:00s\n","epoch 92 | loss: 0.0     |  0:00:00s\n","epoch 93 | loss: 0.0     |  0:00:00s\n","epoch 94 | loss: 0.0     |  0:00:00s\n","epoch 95 | loss: 0.0     |  0:00:00s\n","epoch 96 | loss: 0.0     |  0:00:00s\n","epoch 97 | loss: 0.0     |  0:00:00s\n","epoch 98 | loss: 0.0     |  0:00:00s\n","epoch 99 | loss: 0.0     |  0:00:00s\n"]}],"source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","\n","# TabNet 모델 생성\n","tabnet_clf = TabNetClassifier()\n","\n","# DataFrame을 NumPy 배열로 변환\n","x_train_np = x_resampled.values\n","y_train_np = y_resampled.values\n","x_test_np = x_test.values\n","\n","# 모델 훈련\n","tabnet_clf.fit(x_train_np, y_train_np)\n","\n","# 테스트 데이터에 대한 예측\n","tabnet_pred = tabnet_clf.predict(x_test_np)\n","tabnet_pred_proba = tabnet_clf.predict_proba(x_test_np)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1710842255826,"user":{"displayName":"김현아","userId":"04855751482690087207"},"user_tz":-540},"id":"WE2xpjbawLdO","outputId":"3347023f-7d7c-479b-cc40-570fa68b8f6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["TabNet\n","오차행렬\n","[[1163    0]\n"," [   5    0]]\n","정확도: 0.9957, 정밀도 : 0.0000, 재현율:0.0000,F1 스코어:0.0000\n"]}],"source":["# 성능 평가\n","print(\"TabNet\")\n","get_clf_eval(y_test, tabnet_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwYz-FhHCCdV"},"outputs":[],"source":["# from pytorch_tabnet.tab_model import TabNetClassifier\n","# from sklearn.model_selection import GridSearchCV\n","# from sklearn.metrics import make_scorer, accuracy_score\n","\n","# # TabNet 모델 정의\n","# tabnet_clf = TabNetClassifier()\n","\n","# # 그리드 서치를 위한 하이퍼파라미터 그리드 설정\n","# param_grid = {\n","#     'n_d': [8, 16, 32],  # Decision 단위의 피처 개수\n","#     'n_a': [8, 16, 32],  # Attention 단위의 피처 개수\n","#     'n_steps': [3, 5, 10],  # 역전파 단계 수\n","#     'gamma': [1.0, 1.5, 2.0],  # 역전파 시 감마 값\n","#     'lambda_sparse': [0.0001, 0.001, 0.01],  # 희소 손실 정규화 파라미터\n","# }\n","\n","# # 그리드 서치 수행\n","# grid_search = GridSearchCV(tabnet_clf, param_grid=param_grid, cv=5, scoring='accuracy')\n","# grid_search.fit(x_train_np, y_train_np)\n","\n","# # 최적의 모델과 하이퍼파라미터 가져오기\n","# best_tabnet_clf = grid_search.best_estimator_\n","# best_params = grid_search.best_params_\n","\n","# # 테스트 데이터에 대한 예측 수행\n","# tabnet_pred = best_tabnet_clf.predict(x_test)\n","# tabnet_pred_proba = best_tabnet_clf.predict_proba(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONR-DVznwqX2"},"outputs":[],"source":["# # 분류 임계값 조정\n","# threshold = 0.5  # 임계값 설정\n","# tabnet_pred_adjusted = (tabnet_pred_proba[:, 1] >= threshold).astype(int)\n","\n","# 임곗값 조정 후 성능 평가\n","# print(\"TabNet\")\n","# get_clf_eval(y_test, tabnet_pred)"]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n","\n","def evaluate(y_true, y_pred):\n","    # 정확도 (Accuracy)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(\"Accuracy:\", accuracy)\n","\n","    # 정밀도 (Precision)\n","    precision = precision_score(y_true, y_pred)\n","    print(\"Precision:\", precision)\n","\n","    # 재현율 (Recall)\n","    recall = recall_score(y_true, y_pred)\n","    print(\"Recall:\", recall)\n","\n","    # F1 스코어 (F1 Score)\n","    f1 = f1_score(y_true, y_pred)\n","    print(\"F1 Score:\", f1)\n","\n","    # AUC-ROC\n","    try:\n","        auc_roc = roc_auc_score(y_true, y_pred)\n","        print(\"AUC-ROC:\", auc_roc)\n","    except ValueError:\n","        print(\"AUC-ROC cannot be calculated for multiclass classification.\")"],"metadata":{"id":"DTGXeIwbjm1U","executionInfo":{"status":"ok","timestamp":1711005542230,"user_tz":-540,"elapsed":462,"user":{"displayName":"김현아","userId":"04855751482690087207"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["#### 2. LSTM"],"metadata":{"id":"amWYcuieU-9C"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","\n","# Model Building\n","model = Sequential()\n","model.add(LSTM(128, activation='relu', input_shape=(x_resampled.shape[1],1)))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Model Compilation\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Model Training\n","model.fit(x_resampled, y_resampled, epochs=100, batch_size=64)\n","\n","# 모델 평가\n","y_pred = model.predict(x_test)\n","predictions_binary = (y_pred > 0.5).astype(int)\n","\n","evaluate(y_test, predictions_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRns7Jrdg8sB","executionInfo":{"status":"ok","timestamp":1710970671217,"user_tz":-540,"elapsed":14804,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"0a06b2e0-3b5f-420e-eb45-8c21f623e93c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","4/4 [==============================] - 2s 26ms/step - loss: 0.6829 - accuracy: 0.7607\n","Epoch 2/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.6657 - accuracy: 0.7692\n","Epoch 3/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.6474 - accuracy: 0.7692\n","Epoch 4/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.6248 - accuracy: 0.7692\n","Epoch 5/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.5885 - accuracy: 0.7735\n","Epoch 6/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.5320 - accuracy: 0.7906\n","Epoch 7/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.4501 - accuracy: 0.8077\n","Epoch 8/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.3549 - accuracy: 0.8376\n","Epoch 9/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.3244 - accuracy: 0.8547\n","Epoch 10/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.2883 - accuracy: 0.8803\n","Epoch 11/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2856 - accuracy: 0.8761\n","Epoch 12/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2722 - accuracy: 0.8846\n","Epoch 13/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2814 - accuracy: 0.8846\n","Epoch 14/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2728 - accuracy: 0.8761\n","Epoch 15/100\n","4/4 [==============================] - 0s 28ms/step - loss: 0.2726 - accuracy: 0.8846\n","Epoch 16/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2634 - accuracy: 0.8974\n","Epoch 17/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2672 - accuracy: 0.8761\n","Epoch 18/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2687 - accuracy: 0.8932\n","Epoch 19/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2651 - accuracy: 0.8932\n","Epoch 20/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2613 - accuracy: 0.8932\n","Epoch 21/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2569 - accuracy: 0.8932\n","Epoch 22/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2585 - accuracy: 0.8932\n","Epoch 23/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2513 - accuracy: 0.8932\n","Epoch 24/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2555 - accuracy: 0.8974\n","Epoch 25/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2531 - accuracy: 0.8932\n","Epoch 26/100\n","4/4 [==============================] - 0s 28ms/step - loss: 0.2585 - accuracy: 0.8974\n","Epoch 27/100\n","4/4 [==============================] - 0s 28ms/step - loss: 0.2491 - accuracy: 0.8932\n","Epoch 28/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2524 - accuracy: 0.8932\n","Epoch 29/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2527 - accuracy: 0.8974\n","Epoch 30/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2489 - accuracy: 0.9017\n","Epoch 31/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2523 - accuracy: 0.9017\n","Epoch 32/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2485 - accuracy: 0.9060\n","Epoch 33/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.2464 - accuracy: 0.8974\n","Epoch 34/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2487 - accuracy: 0.9017\n","Epoch 35/100\n","4/4 [==============================] - 0s 30ms/step - loss: 0.2629 - accuracy: 0.9060\n","Epoch 36/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2521 - accuracy: 0.8974\n","Epoch 37/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2501 - accuracy: 0.9017\n","Epoch 38/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2545 - accuracy: 0.8974\n","Epoch 39/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2476 - accuracy: 0.9017\n","Epoch 40/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2548 - accuracy: 0.8974\n","Epoch 41/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.2554 - accuracy: 0.8974\n","Epoch 42/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2544 - accuracy: 0.8974\n","Epoch 43/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2478 - accuracy: 0.8932\n","Epoch 44/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2468 - accuracy: 0.9017\n","Epoch 45/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2469 - accuracy: 0.9103\n","Epoch 46/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2471 - accuracy: 0.8974\n","Epoch 47/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2502 - accuracy: 0.9060\n","Epoch 48/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2386 - accuracy: 0.9103\n","Epoch 49/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.2410 - accuracy: 0.9060\n","Epoch 50/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2420 - accuracy: 0.9060\n","Epoch 51/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2424 - accuracy: 0.9060\n","Epoch 52/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2394 - accuracy: 0.9103\n","Epoch 53/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2415 - accuracy: 0.9103\n","Epoch 54/100\n","4/4 [==============================] - 0s 31ms/step - loss: 0.2332 - accuracy: 0.9060\n","Epoch 55/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2384 - accuracy: 0.9145\n","Epoch 56/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2381 - accuracy: 0.9060\n","Epoch 57/100\n","4/4 [==============================] - 0s 27ms/step - loss: 0.2365 - accuracy: 0.9060\n","Epoch 58/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2320 - accuracy: 0.9103\n","Epoch 59/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2327 - accuracy: 0.9060\n","Epoch 60/100\n","4/4 [==============================] - 0s 23ms/step - loss: 0.2345 - accuracy: 0.9103\n","Epoch 61/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2340 - accuracy: 0.9145\n","Epoch 62/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2323 - accuracy: 0.9145\n","Epoch 63/100\n","4/4 [==============================] - 0s 29ms/step - loss: 0.2248 - accuracy: 0.9103\n","Epoch 64/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2277 - accuracy: 0.9103\n","Epoch 65/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2300 - accuracy: 0.9145\n","Epoch 66/100\n","4/4 [==============================] - 0s 25ms/step - loss: 0.2254 - accuracy: 0.9145\n","Epoch 67/100\n","4/4 [==============================] - 0s 26ms/step - loss: 0.2267 - accuracy: 0.9103\n","Epoch 68/100\n","4/4 [==============================] - 0s 22ms/step - loss: 0.2348 - accuracy: 0.9103\n","Epoch 69/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2264 - accuracy: 0.9145\n","Epoch 70/100\n","4/4 [==============================] - 0s 45ms/step - loss: 0.2180 - accuracy: 0.9103\n","Epoch 71/100\n","4/4 [==============================] - 0s 44ms/step - loss: 0.2428 - accuracy: 0.8974\n","Epoch 72/100\n","4/4 [==============================] - 0s 46ms/step - loss: 0.6089 - accuracy: 0.9103\n","Epoch 73/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.2778 - accuracy: 0.8718\n","Epoch 74/100\n","4/4 [==============================] - 0s 36ms/step - loss: 0.2734 - accuracy: 0.9017\n","Epoch 75/100\n","4/4 [==============================] - 0s 38ms/step - loss: 0.2722 - accuracy: 0.8846\n","Epoch 76/100\n","4/4 [==============================] - 0s 43ms/step - loss: 0.2547 - accuracy: 0.8889\n","Epoch 77/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.2534 - accuracy: 0.9103\n","Epoch 78/100\n","4/4 [==============================] - 0s 45ms/step - loss: 0.2370 - accuracy: 0.8803\n","Epoch 79/100\n","4/4 [==============================] - 0s 37ms/step - loss: 0.2430 - accuracy: 0.8932\n","Epoch 80/100\n","4/4 [==============================] - 0s 37ms/step - loss: 0.2444 - accuracy: 0.8974\n","Epoch 81/100\n","4/4 [==============================] - 0s 40ms/step - loss: 0.2382 - accuracy: 0.9145\n","Epoch 82/100\n","4/4 [==============================] - 0s 42ms/step - loss: 0.2428 - accuracy: 0.9017\n","Epoch 83/100\n","4/4 [==============================] - 0s 33ms/step - loss: 0.2410 - accuracy: 0.9017\n","Epoch 84/100\n","4/4 [==============================] - 0s 40ms/step - loss: 0.2370 - accuracy: 0.9145\n","Epoch 85/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.2370 - accuracy: 0.9103\n","Epoch 86/100\n","4/4 [==============================] - 0s 38ms/step - loss: 0.2355 - accuracy: 0.9103\n","Epoch 87/100\n","4/4 [==============================] - 0s 37ms/step - loss: 0.2299 - accuracy: 0.9060\n","Epoch 88/100\n","4/4 [==============================] - 0s 38ms/step - loss: 0.2303 - accuracy: 0.9145\n","Epoch 89/100\n","4/4 [==============================] - 0s 37ms/step - loss: 0.2331 - accuracy: 0.9145\n","Epoch 90/100\n","4/4 [==============================] - 0s 42ms/step - loss: 0.2236 - accuracy: 0.9103\n","Epoch 91/100\n","4/4 [==============================] - 0s 40ms/step - loss: 0.2297 - accuracy: 0.9103\n","Epoch 92/100\n","4/4 [==============================] - 0s 41ms/step - loss: 0.2266 - accuracy: 0.9188\n","Epoch 93/100\n","4/4 [==============================] - 0s 39ms/step - loss: 0.2298 - accuracy: 0.9060\n","Epoch 94/100\n","4/4 [==============================] - 0s 38ms/step - loss: 0.2275 - accuracy: 0.9060\n","Epoch 95/100\n","4/4 [==============================] - 0s 42ms/step - loss: 0.2306 - accuracy: 0.9060\n","Epoch 96/100\n","4/4 [==============================] - 0s 41ms/step - loss: 0.2266 - accuracy: 0.9060\n","Epoch 97/100\n","4/4 [==============================] - 0s 50ms/step - loss: 0.2259 - accuracy: 0.9103\n","Epoch 98/100\n","4/4 [==============================] - 0s 38ms/step - loss: 0.2178 - accuracy: 0.9145\n","Epoch 99/100\n","4/4 [==============================] - 0s 31ms/step - loss: 0.2296 - accuracy: 0.8974\n","Epoch 100/100\n","4/4 [==============================] - 0s 24ms/step - loss: 0.2317 - accuracy: 0.9017\n","37/37 [==============================] - 0s 7ms/step\n","Accuracy: 0.9452054794520548\n","Precision: 0.05970149253731343\n","Recall: 0.8\n","F1 Score: 0.11111111111111112\n","AUC-ROC: 0.8729148753224419\n"]}]},{"cell_type":"code","source":["# 임계값에 따라 예측값 조정\n","threshold = 0.3 # 기본 임계값\n","\n","predictions_binary = (y_pred > threshold).astype(int)\n","evaluate(y_test, predictions_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fv-QPpAum72A","executionInfo":{"status":"ok","timestamp":1710970671217,"user_tz":-540,"elapsed":26,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"ba4a57ed-fb6c-4c65-e07b-9b601d24cd16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.898972602739726\n","Precision: 0.04065040650406504\n","Recall: 1.0\n","F1 Score: 0.078125\n","AUC-ROC: 0.9492691315563199\n"]}]},{"cell_type":"markdown","source":["#### 3. CNN"],"metadata":{"id":"q3StNKlHVJAv"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","\n","# 모델 생성\n","model = Sequential()\n","model.add(Conv1D(128, 3, activation='relu', input_shape=(x_resampled.shape[1],1)))\n","model.add(MaxPooling1D(3))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 모델 학습\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(x_resampled, y_resampled, epochs=100, batch_size=64)\n","\n","# 모델 평가\n","y_pred = model.predict(x_test)\n","\n","predictions_binary = (y_pred > 0.5).astype(int)\n","evaluate(y_test, predictions_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cUL2Pklmj-kE","executionInfo":{"status":"ok","timestamp":1710970675783,"user_tz":-540,"elapsed":4586,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"b9103098-b6d5-4e46-b1f6-231100345b85"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","4/4 [==============================] - 1s 8ms/step - loss: 0.6464 - accuracy: 0.7735\n","Epoch 2/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.8504\n","Epoch 3/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.8675\n","Epoch 4/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8761\n","Epoch 5/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8675\n","Epoch 6/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8675\n","Epoch 7/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8761\n","Epoch 8/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.3100 - accuracy: 0.8889\n","Epoch 9/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2790 - accuracy: 0.8846\n","Epoch 10/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2630 - accuracy: 0.9017\n","Epoch 11/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.2644 - accuracy: 0.8846\n","Epoch 12/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2522 - accuracy: 0.8932\n","Epoch 13/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2447 - accuracy: 0.9017\n","Epoch 14/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.2331 - accuracy: 0.8932\n","Epoch 15/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2163 - accuracy: 0.9103\n","Epoch 16/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2206 - accuracy: 0.8932\n","Epoch 17/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2166 - accuracy: 0.9017\n","Epoch 18/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2277 - accuracy: 0.8932\n","Epoch 19/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2192 - accuracy: 0.9060\n","Epoch 20/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.2020 - accuracy: 0.9017\n","Epoch 21/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2140 - accuracy: 0.9188\n","Epoch 22/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2277 - accuracy: 0.8889\n","Epoch 23/100\n","4/4 [==============================] - 0s 8ms/step - loss: 0.2183 - accuracy: 0.9060\n","Epoch 24/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2268 - accuracy: 0.9060\n","Epoch 25/100\n","4/4 [==============================] - 0s 9ms/step - loss: 0.1993 - accuracy: 0.9103\n","Epoch 26/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2195 - accuracy: 0.9017\n","Epoch 27/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.9231\n","Epoch 28/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.2060 - accuracy: 0.9103\n","Epoch 29/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2100 - accuracy: 0.8974\n","Epoch 30/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1942 - accuracy: 0.9145\n","Epoch 31/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1874 - accuracy: 0.9103\n","Epoch 32/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.2042 - accuracy: 0.9060\n","Epoch 33/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.2050 - accuracy: 0.9103\n","Epoch 34/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.1988 - accuracy: 0.9188\n","Epoch 35/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1997 - accuracy: 0.8974\n","Epoch 36/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1852 - accuracy: 0.9145\n","Epoch 37/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9188\n","Epoch 38/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1865 - accuracy: 0.9145\n","Epoch 39/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1883 - accuracy: 0.9231\n","Epoch 40/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.2007 - accuracy: 0.9231\n","Epoch 41/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.2096 - accuracy: 0.9103\n","Epoch 42/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1917 - accuracy: 0.9103\n","Epoch 43/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1840 - accuracy: 0.9188\n","Epoch 44/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9231\n","Epoch 45/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1915 - accuracy: 0.9188\n","Epoch 46/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1746 - accuracy: 0.9231\n","Epoch 47/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9274\n","Epoch 48/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1750 - accuracy: 0.9231\n","Epoch 49/100\n","4/4 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.9188\n","Epoch 50/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1733 - accuracy: 0.9145\n","Epoch 51/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1692 - accuracy: 0.9274\n","Epoch 52/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.9359\n","Epoch 53/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1673 - accuracy: 0.9231\n","Epoch 54/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1769 - accuracy: 0.9274\n","Epoch 55/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1671 - accuracy: 0.9274\n","Epoch 56/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1656 - accuracy: 0.9274\n","Epoch 57/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.9231\n","Epoch 58/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1632 - accuracy: 0.9188\n","Epoch 59/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1674 - accuracy: 0.9231\n","Epoch 60/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.9316\n","Epoch 61/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.9188\n","Epoch 62/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1650 - accuracy: 0.9359\n","Epoch 63/100\n","4/4 [==============================] - 0s 8ms/step - loss: 0.1594 - accuracy: 0.9316\n","Epoch 64/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1563 - accuracy: 0.9274\n","Epoch 65/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1698 - accuracy: 0.9188\n","Epoch 66/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1583 - accuracy: 0.9316\n","Epoch 67/100\n","4/4 [==============================] - 0s 9ms/step - loss: 0.1664 - accuracy: 0.9316\n","Epoch 68/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.9316\n","Epoch 69/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.9316\n","Epoch 70/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.9359\n","Epoch 71/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.9402\n","Epoch 72/100\n","4/4 [==============================] - 0s 8ms/step - loss: 0.1639 - accuracy: 0.9274\n","Epoch 73/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1606 - accuracy: 0.9274\n","Epoch 74/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1481 - accuracy: 0.9402\n","Epoch 75/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1419 - accuracy: 0.9359\n","Epoch 76/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.9402\n","Epoch 77/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1598 - accuracy: 0.9316\n","Epoch 78/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1456 - accuracy: 0.9359\n","Epoch 79/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1481 - accuracy: 0.9402\n","Epoch 80/100\n","4/4 [==============================] - 0s 9ms/step - loss: 0.1447 - accuracy: 0.9402\n","Epoch 81/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1376 - accuracy: 0.9402\n","Epoch 82/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1503 - accuracy: 0.9274\n","Epoch 83/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.9444\n","Epoch 84/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1401 - accuracy: 0.9487\n","Epoch 85/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1431 - accuracy: 0.9487\n","Epoch 86/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1449 - accuracy: 0.9359\n","Epoch 87/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9359\n","Epoch 88/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.9444\n","Epoch 89/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.9316\n","Epoch 90/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9444\n","Epoch 91/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9359\n","Epoch 92/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1452 - accuracy: 0.9402\n","Epoch 93/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1362 - accuracy: 0.9487\n","Epoch 94/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1371 - accuracy: 0.9487\n","Epoch 95/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1403 - accuracy: 0.9359\n","Epoch 96/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 0.9487\n","Epoch 97/100\n","4/4 [==============================] - 0s 7ms/step - loss: 0.1402 - accuracy: 0.9444\n","Epoch 98/100\n","4/4 [==============================] - 0s 11ms/step - loss: 0.1350 - accuracy: 0.9316\n","Epoch 99/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1385 - accuracy: 0.9402\n","Epoch 100/100\n","4/4 [==============================] - 0s 6ms/step - loss: 0.1243 - accuracy: 0.9573\n","37/37 [==============================] - 0s 2ms/step\n","Accuracy: 0.9563356164383562\n","Precision: 0.08928571428571429\n","Recall: 1.0\n","F1 Score: 0.1639344262295082\n","AUC-ROC: 0.9780739466895958\n"]}]},{"cell_type":"code","source":["# 임계값에 따라 예측값 조정\n","threshold = 0.3 # 기본 임계값\n","\n","predictions_binary = (y_pred > threshold).astype(int)\n","evaluate(y_test, predictions_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7VO5RxtlmPn0","executionInfo":{"status":"ok","timestamp":1710970824537,"user_tz":-540,"elapsed":295,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"40a66bc9-6d79-41f7-a407-af0ad542b494"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9332191780821918\n","Precision: 0.060240963855421686\n","Recall: 1.0\n","F1 Score: 0.11363636363636363\n","AUC-ROC: 0.9664660361134996\n"]}]},{"cell_type":"markdown","source":["#### 교차검증"],"metadata":{"id":"NrkPJ5sj4jRE"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","# STRAtified k-fold를 위한 설정\n","k_folds = 5  # k를 설정합니다.\n","stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n","\n","# 교차 검증 수행\n","accuracies = []  # 각 fold의 정확도를 저장할 리스트\n","\n","for fold, (train_idx, val_idx) in enumerate(stratified_kfold.split(x_train, y_train)):\n","    print(f\"Fold {fold+1}/{k_folds}\")\n","\n","    # Fold에 따라 데이터 분할\n","    X_train_fold, X_val_fold = x_train.iloc[train_idx], x_train.iloc[val_idx]\n","    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n","\n","    # undersampling 수행\n","    rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n","    X_train_resampled, y_train_resampled = rus.fit_resample(X_train_fold, y_train_fold)\n","\n","    X_train_resampled = X_train_resampled.values.reshape(X_train_resampled.shape[0], 1, X_train_resampled.shape[1])\n","    y_train_resampled = y_train_resampled.values\n","\n","    # 모델 생성\n","    model = Sequential()\n","    model.add(LSTM(128, activation='relu', input_shape=(X_train_resampled.shape[1:])))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    # 모델 컴파일\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    # 모델 학습\n","    model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=64, verbose=0)  # verbose=0으로 설정하여 학습 과정 출력 생략\n","\n","    # 검증 데이터에 대한 예측 및 평가\n","    X_val_fold = X_val_fold.values.reshape(X_val_fold.shape[0], 1, X_val_fold.shape[1])\n","    y_pred = model.predict(X_val_fold)\n","\n","    # 이진 분류로 변환\n","    y_pred_binary = (y_pred > 0.3).astype(int)\n","\n","    evaluate(y_val_fold,y_pred_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g3kqNAsY4kRL","executionInfo":{"status":"ok","timestamp":1711005911130,"user_tz":-540,"elapsed":38373,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"32fe8bdf-b1d3-450b-8cb7-75e73becf2ee"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1/5\n","22/22 [==============================] - 0s 2ms/step\n","Accuracy: 0.9583931133428981\n","Precision: 0.1724137931034483\n","Recall: 0.5\n","F1 Score: 0.25641025641025644\n","AUC-ROC: 0.7325327510917031\n","Fold 2/5\n","22/22 [==============================] - 0s 2ms/step\n","Accuracy: 0.945480631276901\n","Precision: 0.18604651162790697\n","Recall: 0.7272727272727273\n","F1 Score: 0.2962962962962963\n","AUC-ROC: 0.838126159554731\n","Fold 3/5\n","22/22 [==============================] - 0s 2ms/step\n","Accuracy: 0.9598278335724534\n","Precision: 0.2571428571428571\n","Recall: 0.8181818181818182\n","F1 Score: 0.39130434782608686\n","AUC-ROC: 0.8901404717731249\n","Fold 4/5\n","22/22 [==============================] - 0s 4ms/step\n","Accuracy: 0.9497847919655668\n","Precision: 0.2\n","Recall: 0.7272727272727273\n","F1 Score: 0.3137254901960785\n","AUC-ROC: 0.8403127484760137\n","Fold 5/5\n","22/22 [==============================] - 0s 4ms/step\n","Accuracy: 0.945480631276901\n","Precision: 0.22448979591836735\n","Recall: 1.0\n","F1 Score: 0.36666666666666664\n","AUC-ROC: 0.9723032069970846\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2EKDVb_-4n3R","executionInfo":{"status":"ok","timestamp":1711005911131,"user_tz":-540,"elapsed":17,"user":{"displayName":"김현아","userId":"04855751482690087207"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import accuracy_score\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","# STRAtified k-fold를 위한 설정\n","k_folds = 5  # k를 설정합니다.\n","stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n","\n","feature =x_train\n","label = y_train\n","\n","# 교차 검증 수행\n","accuracies = []  # 각 fold의 정확도를 저장할 리스트\n","\n","for fold, (train_idx, val_idx) in enumerate(stratified_kfold.split(feature, label)):\n","    print(f\"Fold {fold+1}/{k_folds}\")\n","\n","    # Fold에 따라 데이터 분할\n","    X_train_fold, X_val_fold = feature.iloc[train_idx], feature.iloc[val_idx]\n","    y_train_fold, y_val_fold = label.iloc[train_idx], label.iloc[val_idx]\n","\n","    # undersampling 수행\n","    rus = RandomUnderSampler(sampling_strategy=0.1, random_state=42)\n","    X_train_resampled, y_train_resampled = rus.fit_resample(X_train_fold, y_train_fold)\n","\n","    X_train_resampled = X_train_resampled.values.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n","    y_train_resampled = y_train_resampled.values\n","\n","    # 모델 생성\n","    model = Sequential()\n","    model.add(Conv1D(128, 3, activation='relu', input_shape=(X_train_resampled.shape[1:])))\n","    model.add(MaxPooling1D(3))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    # 모델 학습\n","    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    model.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=64, verbose=0)  # verbose=0으로 설정하여 학습 과정 출력 생략\n","\n","    # 검증 데이터에 대한 예측 및 평가\n","    X_val_fold = X_val_fold.values.reshape(X_val_fold.shape[0], X_val_fold.shape[1], 1)\n","    y_pred = model.predict(X_val_fold)\n","    predictions_binary = (y_pred > 0.3).astype(int)\n","    evaluate(y_val_fold, predictions_binary)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4IwJMHu4srk","executionInfo":{"status":"ok","timestamp":1711005943638,"user_tz":-540,"elapsed":32524,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"fae0428e-17ac-4537-c1f1-49a337732e53"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1/5\n","22/22 [==============================] - 0s 2ms/step\n","Accuracy: 0.9497847919655668\n","Precision: 0.16216216216216217\n","Recall: 0.6\n","F1 Score: 0.25531914893617025\n","AUC-ROC: 0.7774381368267831\n","Fold 2/5\n","22/22 [==============================] - 0s 3ms/step\n","Accuracy: 0.9540889526542324\n","Precision: 0.21621621621621623\n","Recall: 0.7272727272727273\n","F1 Score: 0.33333333333333337\n","AUC-ROC: 0.8424993373972967\n","Fold 3/5\n","22/22 [==============================] - 0s 2ms/step\n","Accuracy: 0.9512195121951219\n","Precision: 0.23255813953488372\n","Recall: 0.9090909090909091\n","F1 Score: 0.3703703703703703\n","AUC-ROC: 0.9304929764113438\n","Fold 4/5\n","22/22 [==============================] - 0s 3ms/step\n","Accuracy: 0.9512195121951219\n","Precision: 0.1891891891891892\n","Recall: 0.6363636363636364\n","F1 Score: 0.2916666666666667\n","AUC-ROC: 0.7963159289689901\n","Fold 5/5\n","22/22 [==============================] - 0s 2ms/step\n","Accuracy: 0.9354375896700143\n","Precision: 0.19642857142857142\n","Recall: 1.0\n","F1 Score: 0.3283582089552239\n","AUC-ROC: 0.967201166180758\n"]}]},{"cell_type":"code","source":["!pip install pytorch_tabnet.tab_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inXPe3787DRN","executionInfo":{"status":"ok","timestamp":1711005944765,"user_tz":-540,"elapsed":1135,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"e2675880-eb89-40ab-e3ce-ff0d137713ab"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch_tabnet.tab_model (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch_tabnet.tab_model\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["from pytorch_tabnet.tab_model import TabNetClassifier\n","from imblearn.under_sampling import RandomUnderSampler\n","import torch\n","\n","X= x_train\n","y=y_train\n","\n","rus = RandomUnderSampler(sampling_strategy=0.1)\n","X_resampled, y_resampled = rus.fit_resample(X, y)\n","\n","X = X_resampled.values\n","y = y_resampled.values\n","\n","# x_test, y_test = label_split(test_s)\n","\n","X_test = x_test.values\n","y_test = y_test.values\n","\n","# STRAtified k-fold를 위한 설정\n","k_folds = 5  # k를 설정합니다.\n","stratified_kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n","\n","# 교차 검증 수행\n","accuracies = []  # 각 fold의 정확도를 저장할 리스트\n","\n","for fold, (train_idx, val_idx) in enumerate(stratified_kfold.split(X, y)):\n","    print(f\"Fold {fold+1}/{k_folds}\")\n","\n","    # Fold에 따라 데이터 분할\n","    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n","    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n","\n","    # 모델 생성\n","    clf = TabNetClassifier(\n","        n_d=8, n_a=8,\n","        optimizer_fn=torch.optim.Adam,\n","        scheduler_fn=torch.optim.lr_scheduler.CosineAnnealingLR,\n","        scheduler_params={'T_max': 100}\n","    )\n","\n","    # 모델 학습\n","    clf.fit(\n","        X_train_fold, y_train_fold,\n","        eval_set=[(X_val_fold, y_val_fold)],\n","        eval_metric=['accuracy'],\n","        max_epochs=100,\n","        patience=20,  # 조기 종료를 위한 설정\n","        batch_size=1024,  # 배치 사이즈 설정\n","        virtual_batch_size=128,  # 가상 배치 사이즈 설정\n","        num_workers=0,  # 사용할 워커 수 설정\n","        drop_last=False\n","    )\n","\n","    # 검증 데이터에 대한 예측\n","    y_pred = clf.predict(X_test)\n","    evaluate(y_test, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnmHtdZx4xN3","executionInfo":{"status":"ok","timestamp":1711007577636,"user_tz":-540,"elapsed":24126,"user":{"displayName":"김현아","userId":"04855751482690087207"}},"outputId":"fcc08297-d914-420e-f7ce-9d5aa0f6f10c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Fold 1/5\n","epoch 0  | loss: 0.53096 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 1  | loss: 0.41422 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 2  | loss: 0.35532 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 3  | loss: 0.36587 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 4  | loss: 0.30267 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 5  | loss: 0.29398 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 6  | loss: 0.293   | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 7  | loss: 0.26372 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 8  | loss: 0.24227 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 9  | loss: 0.23643 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 10 | loss: 0.24521 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 11 | loss: 0.20795 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 12 | loss: 0.20676 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 13 | loss: 0.20082 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 14 | loss: 0.20401 | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 15 | loss: 0.21116 | val_0_accuracy: 0.89916 |  0:00:02s\n","epoch 16 | loss: 0.19271 | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 17 | loss: 0.19171 | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 18 | loss: 0.18304 | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 19 | loss: 0.20688 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 20 | loss: 0.18564 | val_0_accuracy: 0.92437 |  0:00:03s\n","epoch 21 | loss: 0.16638 | val_0_accuracy: 0.92437 |  0:00:03s\n","epoch 22 | loss: 0.17633 | val_0_accuracy: 0.91597 |  0:00:03s\n","epoch 23 | loss: 0.17667 | val_0_accuracy: 0.91597 |  0:00:03s\n","epoch 24 | loss: 0.16955 | val_0_accuracy: 0.90756 |  0:00:03s\n","epoch 25 | loss: 0.16237 | val_0_accuracy: 0.89916 |  0:00:03s\n","epoch 26 | loss: 0.16901 | val_0_accuracy: 0.89916 |  0:00:04s\n","epoch 27 | loss: 0.18736 | val_0_accuracy: 0.89916 |  0:00:04s\n","epoch 28 | loss: 0.16108 | val_0_accuracy: 0.89916 |  0:00:04s\n","epoch 29 | loss: 0.16866 | val_0_accuracy: 0.90756 |  0:00:04s\n","epoch 30 | loss: 0.14471 | val_0_accuracy: 0.91597 |  0:00:04s\n","epoch 31 | loss: 0.15367 | val_0_accuracy: 0.91597 |  0:00:04s\n","epoch 32 | loss: 0.14524 | val_0_accuracy: 0.91597 |  0:00:04s\n","epoch 33 | loss: 0.15458 | val_0_accuracy: 0.93277 |  0:00:04s\n","epoch 34 | loss: 0.16746 | val_0_accuracy: 0.93277 |  0:00:04s\n","epoch 35 | loss: 0.1385  | val_0_accuracy: 0.93277 |  0:00:04s\n","epoch 36 | loss: 0.1452  | val_0_accuracy: 0.93277 |  0:00:04s\n","epoch 37 | loss: 0.14297 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 38 | loss: 0.1285  | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 39 | loss: 0.1333  | val_0_accuracy: 0.94118 |  0:00:05s\n","epoch 40 | loss: 0.12077 | val_0_accuracy: 0.94118 |  0:00:05s\n","epoch 41 | loss: 0.13076 | val_0_accuracy: 0.92437 |  0:00:05s\n","epoch 42 | loss: 0.12445 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 43 | loss: 0.12389 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 44 | loss: 0.12118 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 45 | loss: 0.13207 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 46 | loss: 0.12096 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 47 | loss: 0.11327 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 48 | loss: 0.13943 | val_0_accuracy: 0.93277 |  0:00:06s\n","epoch 49 | loss: 0.11328 | val_0_accuracy: 0.92437 |  0:00:06s\n","epoch 50 | loss: 0.11743 | val_0_accuracy: 0.92437 |  0:00:06s\n","epoch 51 | loss: 0.1375  | val_0_accuracy: 0.91597 |  0:00:06s\n","epoch 52 | loss: 0.11694 | val_0_accuracy: 0.92437 |  0:00:06s\n","epoch 53 | loss: 0.10994 | val_0_accuracy: 0.91597 |  0:00:06s\n","epoch 54 | loss: 0.12801 | val_0_accuracy: 0.90756 |  0:00:06s\n","epoch 55 | loss: 0.10792 | val_0_accuracy: 0.90756 |  0:00:06s\n","epoch 56 | loss: 0.10754 | val_0_accuracy: 0.90756 |  0:00:06s\n","epoch 57 | loss: 0.10209 | val_0_accuracy: 0.90756 |  0:00:06s\n","epoch 58 | loss: 0.10748 | val_0_accuracy: 0.90756 |  0:00:06s\n","epoch 59 | loss: 0.10712 | val_0_accuracy: 0.90756 |  0:00:07s\n","\n","Early stopping occurred at epoch 59 with best_epoch = 39 and best_val_0_accuracy = 0.94118\n","Accuracy: 0.9666095890410958\n","Precision: 0.05263157894736842\n","Recall: 0.4\n","F1 Score: 0.09302325581395349\n","AUC-ROC: 0.6845227858985382\n","Fold 2/5\n","epoch 0  | loss: 0.4758  | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 1  | loss: 0.43825 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 2  | loss: 0.40314 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 3  | loss: 0.34494 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 4  | loss: 0.33533 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 5  | loss: 0.32536 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 6  | loss: 0.2756  | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 7  | loss: 0.25509 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 8  | loss: 0.25596 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 9  | loss: 0.23377 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 10 | loss: 0.23518 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 11 | loss: 0.20737 | val_0_accuracy: 0.89916 |  0:00:01s\n","epoch 12 | loss: 0.22117 | val_0_accuracy: 0.89916 |  0:00:01s\n","epoch 13 | loss: 0.20531 | val_0_accuracy: 0.89916 |  0:00:01s\n","epoch 14 | loss: 0.19231 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 15 | loss: 0.20864 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 16 | loss: 0.20021 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 17 | loss: 0.19637 | val_0_accuracy: 0.89916 |  0:00:01s\n","epoch 18 | loss: 0.19031 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 19 | loss: 0.18285 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 20 | loss: 0.19301 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 21 | loss: 0.18334 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 22 | loss: 0.1761  | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 23 | loss: 0.18571 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 24 | loss: 0.1788  | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 25 | loss: 0.18324 | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 26 | loss: 0.17601 | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 27 | loss: 0.18323 | val_0_accuracy: 0.93277 |  0:00:03s\n","epoch 28 | loss: 0.16971 | val_0_accuracy: 0.93277 |  0:00:03s\n","epoch 29 | loss: 0.1713  | val_0_accuracy: 0.93277 |  0:00:04s\n","epoch 30 | loss: 0.1754  | val_0_accuracy: 0.93277 |  0:00:04s\n","epoch 31 | loss: 0.17663 | val_0_accuracy: 0.92437 |  0:00:04s\n","epoch 32 | loss: 0.17419 | val_0_accuracy: 0.92437 |  0:00:05s\n","epoch 33 | loss: 0.17787 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 34 | loss: 0.17384 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 35 | loss: 0.17335 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 36 | loss: 0.17017 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 37 | loss: 0.15636 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 38 | loss: 0.17339 | val_0_accuracy: 0.93277 |  0:00:05s\n","epoch 39 | loss: 0.15776 | val_0_accuracy: 0.93277 |  0:00:06s\n","epoch 40 | loss: 0.15736 | val_0_accuracy: 0.93277 |  0:00:06s\n","epoch 41 | loss: 0.16083 | val_0_accuracy: 0.93277 |  0:00:06s\n","epoch 42 | loss: 0.14331 | val_0_accuracy: 0.94118 |  0:00:06s\n","epoch 43 | loss: 0.15543 | val_0_accuracy: 0.94958 |  0:00:06s\n","epoch 44 | loss: 0.15543 | val_0_accuracy: 0.94958 |  0:00:06s\n","epoch 45 | loss: 0.16209 | val_0_accuracy: 0.94118 |  0:00:06s\n","epoch 46 | loss: 0.15758 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 47 | loss: 0.15695 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 48 | loss: 0.15312 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 49 | loss: 0.14221 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 50 | loss: 0.14674 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 51 | loss: 0.14687 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 52 | loss: 0.13966 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 53 | loss: 0.14572 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 54 | loss: 0.15574 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 55 | loss: 0.14359 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 56 | loss: 0.15124 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 57 | loss: 0.14079 | val_0_accuracy: 0.94118 |  0:00:07s\n","epoch 58 | loss: 0.14405 | val_0_accuracy: 0.94118 |  0:00:08s\n","epoch 59 | loss: 0.1295  | val_0_accuracy: 0.94118 |  0:00:08s\n","epoch 60 | loss: 0.13501 | val_0_accuracy: 0.94118 |  0:00:08s\n","epoch 61 | loss: 0.13719 | val_0_accuracy: 0.94118 |  0:00:08s\n","epoch 62 | loss: 0.14756 | val_0_accuracy: 0.94118 |  0:00:08s\n","epoch 63 | loss: 0.13211 | val_0_accuracy: 0.94118 |  0:00:08s\n","\n","Early stopping occurred at epoch 63 with best_epoch = 43 and best_val_0_accuracy = 0.94958\n","Accuracy: 0.9863013698630136\n","Precision: 0.13333333333333333\n","Recall: 0.4\n","F1 Score: 0.2\n","AUC-ROC: 0.6944110060189166\n","Fold 3/5\n","epoch 0  | loss: 0.47465 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 1  | loss: 0.45931 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 2  | loss: 0.40784 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 3  | loss: 0.3371  | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 4  | loss: 0.31733 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 5  | loss: 0.2973  | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 6  | loss: 0.28734 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 7  | loss: 0.27573 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 8  | loss: 0.26075 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 9  | loss: 0.25684 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 10 | loss: 0.24916 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 11 | loss: 0.23583 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 12 | loss: 0.23526 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 13 | loss: 0.22837 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 14 | loss: 0.21381 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 15 | loss: 0.20772 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 16 | loss: 0.20201 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 17 | loss: 0.20247 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 18 | loss: 0.1875  | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 19 | loss: 0.18929 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 20 | loss: 0.19976 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 21 | loss: 0.19419 | val_0_accuracy: 0.90756 |  0:00:01s\n","epoch 22 | loss: 0.16662 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 23 | loss: 0.19528 | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 24 | loss: 0.1746  | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 25 | loss: 0.18949 | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 26 | loss: 0.18446 | val_0_accuracy: 0.94118 |  0:00:02s\n","epoch 27 | loss: 0.16098 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 28 | loss: 0.16176 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 29 | loss: 0.15166 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 30 | loss: 0.15809 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 31 | loss: 0.14941 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 32 | loss: 0.14377 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 33 | loss: 0.1479  | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 34 | loss: 0.14906 | val_0_accuracy: 0.89916 |  0:00:02s\n","epoch 35 | loss: 0.13764 | val_0_accuracy: 0.89916 |  0:00:02s\n","epoch 36 | loss: 0.1415  | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 37 | loss: 0.14785 | val_0_accuracy: 0.90756 |  0:00:02s\n","epoch 38 | loss: 0.15885 | val_0_accuracy: 0.89076 |  0:00:02s\n","epoch 39 | loss: 0.13448 | val_0_accuracy: 0.89916 |  0:00:02s\n","epoch 40 | loss: 0.13644 | val_0_accuracy: 0.89916 |  0:00:02s\n","epoch 41 | loss: 0.13342 | val_0_accuracy: 0.89076 |  0:00:03s\n","epoch 42 | loss: 0.13016 | val_0_accuracy: 0.89076 |  0:00:03s\n","epoch 43 | loss: 0.12384 | val_0_accuracy: 0.89916 |  0:00:03s\n","epoch 44 | loss: 0.13433 | val_0_accuracy: 0.89916 |  0:00:03s\n","epoch 45 | loss: 0.12193 | val_0_accuracy: 0.89916 |  0:00:03s\n","epoch 46 | loss: 0.11877 | val_0_accuracy: 0.91597 |  0:00:03s\n","\n","Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_accuracy = 0.94118\n","Accuracy: 0.9768835616438356\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC-ROC: 0.49054170249355117\n","Fold 4/5\n","epoch 0  | loss: 0.50243 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 1  | loss: 0.42167 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 2  | loss: 0.35369 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 3  | loss: 0.35407 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 4  | loss: 0.34831 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 5  | loss: 0.28853 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 6  | loss: 0.28321 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 7  | loss: 0.25705 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 8  | loss: 0.23945 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 9  | loss: 0.23545 | val_0_accuracy: 0.89916 |  0:00:00s\n","epoch 10 | loss: 0.23126 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 11 | loss: 0.21874 | val_0_accuracy: 0.89916 |  0:00:00s\n","epoch 12 | loss: 0.20444 | val_0_accuracy: 0.88235 |  0:00:00s\n","epoch 13 | loss: 0.19353 | val_0_accuracy: 0.88235 |  0:00:00s\n","epoch 14 | loss: 0.19838 | val_0_accuracy: 0.89916 |  0:00:00s\n","epoch 15 | loss: 0.1938  | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 16 | loss: 0.18716 | val_0_accuracy: 0.91597 |  0:00:00s\n","epoch 17 | loss: 0.17985 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 18 | loss: 0.18164 | val_0_accuracy: 0.90756 |  0:00:00s\n","epoch 19 | loss: 0.17517 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 20 | loss: 0.15868 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 21 | loss: 0.15049 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 22 | loss: 0.14446 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 23 | loss: 0.14993 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 24 | loss: 0.17106 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 25 | loss: 0.14289 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 26 | loss: 0.14739 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 27 | loss: 0.16388 | val_0_accuracy: 0.91597 |  0:00:01s\n","epoch 28 | loss: 0.15855 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 29 | loss: 0.15524 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 30 | loss: 0.15285 | val_0_accuracy: 0.94118 |  0:00:01s\n","epoch 31 | loss: 0.15766 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 32 | loss: 0.15667 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 33 | loss: 0.14459 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 34 | loss: 0.12068 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 35 | loss: 0.15153 | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 36 | loss: 0.1279  | val_0_accuracy: 0.93277 |  0:00:01s\n","epoch 37 | loss: 0.14653 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 38 | loss: 0.13942 | val_0_accuracy: 0.92437 |  0:00:01s\n","epoch 39 | loss: 0.15009 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 40 | loss: 0.13267 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 41 | loss: 0.1266  | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 42 | loss: 0.13624 | val_0_accuracy: 0.91597 |  0:00:02s\n","epoch 43 | loss: 0.1285  | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 44 | loss: 0.12047 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 45 | loss: 0.12126 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 46 | loss: 0.1149  | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 47 | loss: 0.14165 | val_0_accuracy: 0.92437 |  0:00:02s\n","epoch 48 | loss: 0.12206 | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 49 | loss: 0.1156  | val_0_accuracy: 0.93277 |  0:00:02s\n","epoch 50 | loss: 0.14446 | val_0_accuracy: 0.93277 |  0:00:02s\n","\n","Early stopping occurred at epoch 50 with best_epoch = 30 and best_val_0_accuracy = 0.94118\n","Accuracy: 0.978595890410959\n","Precision: 0.11538461538461539\n","Recall: 0.6\n","F1 Score: 0.1935483870967742\n","AUC-ROC: 0.7901117798796218\n","Fold 5/5\n","epoch 0  | loss: 0.50175 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 1  | loss: 0.44151 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 2  | loss: 0.37604 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 3  | loss: 0.34598 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 4  | loss: 0.31969 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 5  | loss: 0.29419 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 6  | loss: 0.26687 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 7  | loss: 0.2592  | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 8  | loss: 0.24798 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 9  | loss: 0.23875 | val_0_accuracy: 0.92373 |  0:00:00s\n","epoch 10 | loss: 0.23103 | val_0_accuracy: 0.92373 |  0:00:00s\n","epoch 11 | loss: 0.2323  | val_0_accuracy: 0.92373 |  0:00:00s\n","epoch 12 | loss: 0.20649 | val_0_accuracy: 0.92373 |  0:00:00s\n","epoch 13 | loss: 0.20161 | val_0_accuracy: 0.9322  |  0:00:00s\n","epoch 14 | loss: 0.19567 | val_0_accuracy: 0.94068 |  0:00:00s\n","epoch 15 | loss: 0.18631 | val_0_accuracy: 0.94068 |  0:00:00s\n","epoch 16 | loss: 0.18334 | val_0_accuracy: 0.9322  |  0:00:00s\n","epoch 17 | loss: 0.20098 | val_0_accuracy: 0.92373 |  0:00:00s\n","epoch 18 | loss: 0.16506 | val_0_accuracy: 0.91525 |  0:00:00s\n","epoch 19 | loss: 0.17114 | val_0_accuracy: 0.91525 |  0:00:01s\n","epoch 20 | loss: 0.16269 | val_0_accuracy: 0.90678 |  0:00:01s\n","epoch 21 | loss: 0.15812 | val_0_accuracy: 0.90678 |  0:00:01s\n","epoch 22 | loss: 0.1715  | val_0_accuracy: 0.90678 |  0:00:01s\n","epoch 23 | loss: 0.15052 | val_0_accuracy: 0.90678 |  0:00:01s\n","epoch 24 | loss: 0.14894 | val_0_accuracy: 0.90678 |  0:00:01s\n","epoch 25 | loss: 0.15864 | val_0_accuracy: 0.89831 |  0:00:01s\n","epoch 26 | loss: 0.14759 | val_0_accuracy: 0.89831 |  0:00:01s\n","epoch 27 | loss: 0.14948 | val_0_accuracy: 0.89831 |  0:00:01s\n","epoch 28 | loss: 0.15402 | val_0_accuracy: 0.88136 |  0:00:01s\n","epoch 29 | loss: 0.15207 | val_0_accuracy: 0.89831 |  0:00:01s\n","epoch 30 | loss: 0.1577  | val_0_accuracy: 0.91525 |  0:00:01s\n","epoch 31 | loss: 0.17156 | val_0_accuracy: 0.91525 |  0:00:01s\n","epoch 32 | loss: 0.15053 | val_0_accuracy: 0.90678 |  0:00:01s\n","epoch 33 | loss: 0.16052 | val_0_accuracy: 0.91525 |  0:00:01s\n","epoch 34 | loss: 0.13791 | val_0_accuracy: 0.91525 |  0:00:01s\n","\n","Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_accuracy = 0.94068\n","Accuracy: 0.9863013698630136\n","Precision: 0.0\n","Recall: 0.0\n","F1 Score: 0.0\n","AUC-ROC: 0.49527085124677556\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"16xhcI8RjdD-8xgOKrWmLAt_71X062d-4","timestamp":1710841381903}],"authorship_tag":"ABX9TyOKDpk90AXtHgv82omb1Gd0"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}